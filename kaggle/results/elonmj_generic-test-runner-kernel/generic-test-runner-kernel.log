[{"stream_name":"stdout","time":0.527745589,"data":"================================================================================\n"}
,{"stream_name":"stdout","time":0.527813217,"data":"GENERIC_TEST_TESTS\n"}
,{"stream_name":"stdout","time":0.527819718,"data":"================================================================================\n"}
,{"stream_name":"stdout","time":0.527824272,"data":"Repository: https://github.com/elonmj/Code-traffic-flow.git\n"}
,{"stream_name":"stdout","time":0.527860312,"data":"Branch: main\n"}
,{"stream_name":"stdout","time":0.52793537,"data":"Target: arz_model/tests/\n"}
,{"stream_name":"stdout","time":5.528756947,"data":"Python: 3.11.13 (main, Jun  4 2025, 08:57:29) [GCC 11.4.0]\n"}
,{"stream_name":"stdout","time":5.528793051,"data":"PyTorch: 2.6.0+cu124\n"}
,{"stream_name":"stdout","time":5.575356859,"data":"CUDA available: True\n"}
,{"stream_name":"stdout","time":5.595790647,"data":"CUDA device: Tesla P100-PCIE-16GB\n"}
,{"stream_name":"stdout","time":5.595848702,"data":"\n"}
,{"stream_name":"stdout","time":5.595857142,"data":"[STEP 1/4] Cloning repository from GitHub...\n"}
,{"stream_name":"stdout","time":5.595993089,"data":"Command: git clone --single-branch --branch main --depth 1 https://github.com/elonmj/Code-traffic-flow.git /kaggle/working/Code-traffic-flow\n"}
,{"stream_name":"stdout","time":6.5303186570000005,"data":"[OK] Repository cloned successfully\n"}
,{"stream_name":"stdout","time":6.530372358,"data":"\n"}
,{"stream_name":"stdout","time":6.5303876,"data":"[STEP 2/4] Installing dependencies...\n"}
,{"stream_name":"stdout","time":6.530444739,"data":"Installing pytest...\n"}
,{"stream_name":"stdout","time":10.454855415,"data":"[OK] Dependencies installed\n"}
,{"stream_name":"stdout","time":10.454897529,"data":"\n"}
,{"stream_name":"stdout","time":10.454904428,"data":"[STEP 3/4] Running Target...\n"}
,{"stream_name":"stdout","time":10.454910788,"data":"Target is a directory. Executing pytest...\n"}
,{"stream_name":"stdout","time":10.454915914,"data":"Command: /usr/bin/python3 -m pytest -v /kaggle/working/Code-traffic-flow/arz_model/tests\n"}
,{"stream_name":"stdout","time":12.158162039,"data":"============================= test session starts ==============================\n"}
,{"stream_name":"stdout","time":12.158199455,"data":"platform linux -- Python 3.11.13, pytest-8.4.1, pluggy-1.6.0 -- /usr/bin/python3\n"}
,{"stream_name":"stdout","time":12.158206689,"data":"cachedir: .pytest_cache\n"}
,{"stream_name":"stdout","time":12.158284476,"data":"rootdir: /kaggle/working/Code-traffic-flow/arz_model\n"}
,{"stream_name":"stdout","time":12.158303073999999,"data":"configfile: pytest.ini\n"}
,{"stream_name":"stdout","time":12.158309104,"data":"plugins: anyio-4.11.0, typeguard-4.4.4, langsmith-0.4.8\n"}
,{"stream_name":"stdout","time":17.057889984,"data":"collecting ... collected 21 items\n"}
,{"stream_name":"stdout","time":17.057926089,"data":"\n"}
,{"stream_name":"stdout","time":17.192246584,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolInitialization::test_state_initialization_full_array PASSED [  4%]\n"}
,{"stream_name":"stdout","time":17.197305637,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolInitialization::test_state_initialization_physical_only PASSED [  9%]\n"}
,{"stream_name":"stdout","time":17.20017281,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolInitialization::test_invalid_initialization PASSED [ 14%]\n"}
,{"stream_name":"stdout","time":17.202568833,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolAccess::test_segment_state_access PASSED [ 19%]\n"}
,{"stream_name":"stdout","time":17.205047115,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolAccess::test_road_quality_access PASSED [ 23%]\n"}
,{"stream_name":"stdout","time":17.208111904,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolAccess::test_stream_access PASSED [ 28%]\n"}
,{"stream_name":"stdout","time":17.210876052,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolCheckpointing::test_synchronous_checkpoint PASSED [ 33%]\n"}
,{"stream_name":"stdout","time":17.214755685,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolCheckpointing::test_asynchronous_checkpoint PASSED [ 38%]\n"}
,{"stream_name":"stdout","time":17.218516264,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolCheckpointing::test_checkpoint_invalid_segment PASSED [ 42%]\n"}
,{"stream_name":"stdout","time":17.220886377,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolStreams::test_stream_synchronization PASSED [ 47%]\n"}
,{"stream_name":"stdout","time":17.223362709,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolStreams::test_no_streams_synchronization PASSED [ 52%]\n"}
,{"stream_name":"stdout","time":17.225480726,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolMonitoring::test_memory_statistics PASSED [ 57%]\n"}
,{"stream_name":"stdout","time":17.227550864,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolMonitoring::test_string_representation PASSED [ 61%]\n"}
,{"stream_name":"stdout","time":17.229589234,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolCleanup::test_explicit_cleanup PASSED [ 66%]\n"}
,{"stream_name":"stdout","time":17.231723575,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolCleanup::test_destructor_cleanup PASSED [ 71%]\n"}
,{"stream_name":"stdout","time":17.235798017,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolIntegration::test_multi_segment_workflow PASSED [ 76%]\n"}
,{"stream_name":"stdout","time":17.2388215,"data":"arz_model/tests/test_gpu_memory_pool.py::TestGPUMemoryPoolIntegration::test_memory_persistence PASSED [ 80%]\n"}
,{"stream_name":"stdout","time":20.452652949,"data":"arz_model/tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu FAILED [ 85%]\n"}
,{"stream_name":"stdout","time":20.45359109,"data":"arz_model/tests/test_gpu_only_integration.py::test_gpu_required_error SKIPPED [ 90%]\n"}
,{"stream_name":"stdout","time":20.505959244,"data":"arz_model/tests/test_gpu_only_integration.py::test_no_cpu_transfers_in_loop FAILED [ 95%]\n"}
,{"stream_name":"stdout","time":20.558078082,"data":"arz_model/tests/test_gpu_only_integration.py::test_mass_conservation_gpu FAILED [100%]\n"}
,{"stream_name":"stdout","time":20.558097581,"data":"\n"}
,{"stream_name":"stdout","time":20.558102616,"data":"=================================== FAILURES ===================================\n"}
,{"stream_name":"stdout","time":20.558106633,"data":"____________________ test_simulation_runs_end_to_end_on_gpu ____________________\n"}
,{"stream_name":"stdout","time":20.558110488,"data":"\n"}
,{"stream_name":"stdout","time":20.558114472,"data":"    def test_simulation_runs_end_to_end_on_gpu():\n"}
,{"stream_name":"stdout","time":20.558118307,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":20.558122123,"data":"        Tests that a simple simulation can run from start to finish on the GPU.\n"}
,{"stream_name":"stdout","time":20.558126013,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":20.558129991,"data":"        print(\"Running test: test_simulation_runs_end_to_end_on_gpu\")\n"}
,{"stream_name":"stdout","time":20.558133779,"data":"        try:\n"}
,{"stream_name":"stdout","time":20.558137664,"data":"            config = create_test_config()\n"}
,{"stream_name":"stdout","time":20.558154318,"data":"            network_grid = NetworkGrid.from_config(config)\n"}
,{"stream_name":"stdout","time":20.558158362,"data":"            runner = SimulationRunner(network_grid=network_grid, simulation_config=config, quiet=True)\n"}
,{"stream_name":"stdout","time":20.558162343,"data":"\u003e           results = runner.run()\n"}
,{"stream_name":"stdout","time":20.558166489,"data":"                      ^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":20.558169807,"data":"\n"}
,{"stream_name":"stdout","time":20.55817324,"data":"arz_model/tests/test_gpu_only_integration.py:89: \n"}
,{"stream_name":"stdout","time":20.558176989,"data":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"}
,{"stream_name":"stdout","time":20.558180524,"data":"arz_model/simulation/runner.py:745: in run\n"}
,{"stream_name":"stdout","time":20.558184042,"data":"    return self.network_simulator.run(t_final=sim_t_final)\n"}
,{"stream_name":"stdout","time":20.558187394,"data":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":20.558191194,"data":"arz_model/simulation/execution/network_simulator.py:171: in run\n"}
,{"stream_name":"stdout","time":20.558194768,"data":"    d_U_out = strang_splitting_step_gpu_native(\n"}
,{"stream_name":"stdout","time":20.558198374,"data":"arz_model/numerics/time_integration.py:1199: in strang_splitting_step_gpu_native\n"}
,{"stream_name":"stdout","time":20.558202506,"data":"    d_U_ss = solve_hyperbolic_step_ssp_rk3_gpu_native(d_U_star, dt, grid, params, gpu_pool, seg_id, current_time)\n"}
,{"stream_name":"stdout","time":20.558206343,"data":"             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":20.558210171,"data":"arz_model/numerics/time_integration.py:1246: in solve_hyperbolic_step_ssp_rk3_gpu_native\n"}
,{"stream_name":"stdout","time":20.558213875,"data":"    ssp_rk3_stage_1_kernel(d_U_in, L_U0, dt, d_U1)\n"}
,{"stream_name":"stdout","time":20.558247642,"data":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"}
,{"stream_name":"stdout","time":20.558252019,"data":"\n"}
,{"stream_name":"stdout","time":20.55825543,"data":"self = CUDADispatcher(\u003cfunction ssp_rk3_stage_1_kernel at 0x7c5537ed18a0\u003e)\n"}
,{"stream_name":"stdout","time":20.558259754,"data":"args = (\u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550ef72290\u003e, \u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550ed28810\u003e, 0.01, \u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550c721ed0\u003e)\n"}
,{"stream_name":"stdout","time":20.558265881,"data":"kwargs = {}\n"}
,{"stream_name":"stdout","time":20.558269516,"data":"\n"}
,{"stream_name":"stdout","time":20.55827281,"data":"    def __call__(self, *args, **kwargs):\n"}
,{"stream_name":"stdout","time":20.558276398,"data":"        # An attempt to launch an unconfigured kernel\n"}
,{"stream_name":"stdout","time":20.558281683,"data":"\u003e       raise ValueError(missing_launch_config_msg)\n"}
,{"stream_name":"stdout","time":20.558285369,"data":"E       ValueError: \n"}
,{"stream_name":"stdout","time":20.558289053,"data":"E       Kernel launch configuration was not specified. Use the syntax:\n"}
,{"stream_name":"stdout","time":20.558292866,"data":"E       \n"}
,{"stream_name":"stdout","time":20.558296408,"data":"E       kernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n"}
,{"stream_name":"stdout","time":20.55830015,"data":"E       \n"}
,{"stream_name":"stdout","time":20.558311061,"data":"E       See https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n"}
,{"stream_name":"stdout","time":20.558315111,"data":"\n"}
,{"stream_name":"stdout","time":20.558318494,"data":"/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:715: ValueError\n"}
,{"stream_name":"stdout","time":20.558322341,"data":"\n"}
,{"stream_name":"stdout","time":20.558325729,"data":"During handling of the above exception, another exception occurred:\n"}
,{"stream_name":"stdout","time":20.558329363,"data":"\n"}
,{"stream_name":"stdout","time":20.558332729,"data":"    def test_simulation_runs_end_to_end_on_gpu():\n"}
,{"stream_name":"stdout","time":20.558336512,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":20.558340186,"data":"        Tests that a simple simulation can run from start to finish on the GPU.\n"}
,{"stream_name":"stdout","time":20.558343998,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":20.558347716,"data":"        print(\"Running test: test_simulation_runs_end_to_end_on_gpu\")\n"}
,{"stream_name":"stdout","time":20.558351658,"data":"        try:\n"}
,{"stream_name":"stdout","time":20.558355376,"data":"            config = create_test_config()\n"}
,{"stream_name":"stdout","time":20.558359083,"data":"            network_grid = NetworkGrid.from_config(config)\n"}
,{"stream_name":"stdout","time":20.558362919,"data":"            runner = SimulationRunner(network_grid=network_grid, simulation_config=config, quiet=True)\n"}
,{"stream_name":"stdout","time":20.558366809,"data":"            results = runner.run()\n"}
,{"stream_name":"stdout","time":20.558370449,"data":"    \n"}
,{"stream_name":"stdout","time":20.558373809,"data":"            # Verify results structure\n"}
,{"stream_name":"stdout","time":20.558377246,"data":"            assert \"final_time\" in results\n"}
,{"stream_name":"stdout","time":20.558380664,"data":"            assert \"total_steps\" in results\n"}
,{"stream_name":"stdout","time":20.558384342,"data":"            assert \"final_states\" in results\n"}
,{"stream_name":"stdout","time":20.558388075,"data":"            assert \"seg-1\" in results[\"final_states\"]\n"}
,{"stream_name":"stdout","time":20.558392112,"data":"            assert \"seg-2\" in results[\"final_states\"]\n"}
,{"stream_name":"stdout","time":20.558396028,"data":"    \n"}
,{"stream_name":"stdout","time":20.558399548,"data":"            # Verify state array shape\n"}
,{"stream_name":"stdout","time":20.558402986,"data":"            final_state_seg1 = results[\"final_states\"][\"seg-1\"]\n"}
,{"stream_name":"stdout","time":20.558406638,"data":"            expected_shape = (4, config.segments[0].N + 2 * config.grid.num_ghost_cells)\n"}
,{"stream_name":"stdout","time":20.558410379,"data":"            assert final_state_seg1.shape == expected_shape, f\"Expected shape {expected_shape}, but got {final_state_seg1.shape}\"\n"}
,{"stream_name":"stdout","time":20.558414503,"data":"    \n"}
,{"stream_name":"stdout","time":20.558418032,"data":"            print(\"✅ Test passed. Simulation ran end-to-end and produced valid results.\")\n"}
,{"stream_name":"stdout","time":20.558422914,"data":"        except Exception as e:\n"}
,{"stream_name":"stdout","time":20.558426428,"data":"\u003e           pytest.fail(f\"End-to-end GPU simulation test failed with an exception: {e}\", pytrace=True)\n"}
,{"stream_name":"stdout","time":20.558430353,"data":"E           Failed: End-to-end GPU simulation test failed with an exception: \n"}
,{"stream_name":"stdout","time":20.558433957,"data":"E           Kernel launch configuration was not specified. Use the syntax:\n"}
,{"stream_name":"stdout","time":20.558443051,"data":"E           \n"}
,{"stream_name":"stdout","time":20.558446758,"data":"E           kernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n"}
,{"stream_name":"stdout","time":20.558451281,"data":"E           \n"}
,{"stream_name":"stdout","time":20.558454662,"data":"E           See https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n"}
,{"stream_name":"stdout","time":20.55845858,"data":"\n"}
,{"stream_name":"stdout","time":20.558461915,"data":"arz_model/tests/test_gpu_only_integration.py:105: Failed\n"}
,{"stream_name":"stdout","time":20.558465767,"data":"----------------------------- Captured stdout call -----------------------------\n"}
,{"stream_name":"stdout","time":20.558469541,"data":"Running test: test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":20.558473341,"data":"Finalizing network structure and validating topology...\n"}
,{"stream_name":"stdout","time":20.558477284,"data":"✅ Network topology is valid.\n"}
,{"stream_name":"stdout","time":20.558481195,"data":"✅ GPUMemoryPool initialized:\n"}
,{"stream_name":"stdout","time":20.558484877,"data":"   - Segments: 2\n"}
,{"stream_name":"stdout","time":20.558488391,"data":"   - Total cells: 150\n"}
,{"stream_name":"stdout","time":20.55849203,"data":"   - Ghost cells: 3\n"}
,{"stream_name":"stdout","time":20.558495712,"data":"   - Compute Capability: (6, 0)\n"}
,{"stream_name":"stdout","time":20.558499244,"data":"   - CUDA streams: Enabled\n"}
,{"stream_name":"stdout","time":20.558502974,"data":"   - GPU memory allocated: 0.00 MB\n"}
,{"stream_name":"stdout","time":20.558506641,"data":"  - Preparing GPU topology for network coupling...\n"}
,{"stream_name":"stdout","time":20.558510408,"data":"    - GPU topology prepared and transferred.\n"}
,{"stream_name":"stdout","time":20.558514184,"data":"________________________ test_no_cpu_transfers_in_loop _________________________\n"}
,{"stream_name":"stdout","time":20.558518106,"data":"\n"}
,{"stream_name":"stdout","time":20.558521656,"data":"    def test_no_cpu_transfers_in_loop():\n"}
,{"stream_name":"stdout","time":20.558525433,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":20.558529187,"data":"        Hooks into CUDA transfer functions to verify that no transfers occur\n"}
,{"stream_name":"stdout","time":20.558533063,"data":"        during the main simulation loop.\n"}
,{"stream_name":"stdout","time":20.558536804,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":20.558540508,"data":"        print(\"Running test: test_no_cpu_transfers_in_loop\")\n"}
,{"stream_name":"stdout","time":20.558544407,"data":"    \n"}
,{"stream_name":"stdout","time":20.558547888,"data":"        transfer_log = []\n"}
,{"stream_name":"stdout","time":20.558551557,"data":"        original_to_device = cuda.to_device\n"}
,{"stream_name":"stdout","time":20.558555331,"data":"        original_copy_to_host = cuda.devicearray.DeviceNDArray.copy_to_host\n"}
,{"stream_name":"stdout","time":20.558559121000002,"data":"    \n"}
,{"stream_name":"stdout","time":20.55856268,"data":"        def tracked_to_device(obj, *args, **kwargs):\n"}
,{"stream_name":"stdout","time":20.558566319,"data":"            transfer_log.append(f\"to_device: {type(obj)}\")\n"}
,{"stream_name":"stdout","time":20.558570136,"data":"            return original_to_device(obj, *args, **kwargs)\n"}
,{"stream_name":"stdout","time":20.558573905,"data":"    \n"}
,{"stream_name":"stdout","time":20.558577381,"data":"        def tracked_copy_to_host(self, *args, **kwargs):\n"}
,{"stream_name":"stdout","time":20.558587119,"data":"            transfer_log.append(f\"copy_to_host: shape={self.shape}\")\n"}
,{"stream_name":"stdout","time":20.558591102,"data":"            return original_copy_to_host(self, *args, **kwargs)\n"}
,{"stream_name":"stdout","time":20.558594779,"data":"    \n"}
,{"stream_name":"stdout","time":20.558598292,"data":"        try:\n"}
,{"stream_name":"stdout","time":20.558601881,"data":"            config = create_test_config()\n"}
,{"stream_name":"stdout","time":20.558605384,"data":"    \n"}
,{"stream_name":"stdout","time":20.558608919,"data":"            cuda.to_device = tracked_to_device\n"}
,{"stream_name":"stdout","time":20.558612726,"data":"            cuda.devicearray.DeviceNDArray.copy_to_host = tracked_copy_to_host\n"}
,{"stream_name":"stdout","time":20.558616555,"data":"    \n"}
,{"stream_name":"stdout","time":20.558619993,"data":"            network_grid = NetworkGrid.from_config(config)\n"}
,{"stream_name":"stdout","time":20.558623802,"data":"            runner = SimulationRunner(network_grid=network_grid, simulation_config=config, quiet=True)\n"}
,{"stream_name":"stdout","time":20.558627703,"data":"    \n"}
,{"stream_name":"stdout","time":20.558631268,"data":"            # Test 1: Check transfers during the main `run()` method\n"}
,{"stream_name":"stdout","time":20.558635145,"data":"            transfer_log.clear()\n"}
,{"stream_name":"stdout","time":20.55863878,"data":"\u003e           runner.run()\n"}
,{"stream_name":"stdout","time":20.558642501,"data":"\n"}
,{"stream_name":"stdout","time":20.558646967,"data":"arz_model/tests/test_gpu_only_integration.py:152: \n"}
,{"stream_name":"stdout","time":20.558650814,"data":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"}
,{"stream_name":"stdout","time":20.558654634,"data":"arz_model/simulation/runner.py:745: in run\n"}
,{"stream_name":"stdout","time":20.558658386,"data":"    return self.network_simulator.run(t_final=sim_t_final)\n"}
,{"stream_name":"stdout","time":20.558662199,"data":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":20.558666023,"data":"arz_model/simulation/execution/network_simulator.py:171: in run\n"}
,{"stream_name":"stdout","time":20.558669846,"data":"    d_U_out = strang_splitting_step_gpu_native(\n"}
,{"stream_name":"stdout","time":20.558673704,"data":"arz_model/numerics/time_integration.py:1199: in strang_splitting_step_gpu_native\n"}
,{"stream_name":"stdout","time":20.558677719,"data":"    d_U_ss = solve_hyperbolic_step_ssp_rk3_gpu_native(d_U_star, dt, grid, params, gpu_pool, seg_id, current_time)\n"}
,{"stream_name":"stdout","time":20.558681735,"data":"             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":20.558685615,"data":"arz_model/numerics/time_integration.py:1246: in solve_hyperbolic_step_ssp_rk3_gpu_native\n"}
,{"stream_name":"stdout","time":20.558689477,"data":"    ssp_rk3_stage_1_kernel(d_U_in, L_U0, dt, d_U1)\n"}
,{"stream_name":"stdout","time":20.558693073,"data":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"}
,{"stream_name":"stdout","time":20.558696929,"data":"\n"}
,{"stream_name":"stdout","time":20.558700354,"data":"self = CUDADispatcher(\u003cfunction ssp_rk3_stage_1_kernel at 0x7c5537ed18a0\u003e)\n"}
,{"stream_name":"stdout","time":20.558705274,"data":"args = (\u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550c60a950\u003e, \u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550c7ffc90\u003e, 0.01, \u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550c7fce90\u003e)\n"}
,{"stream_name":"stdout","time":20.558728134,"data":"kwargs = {}\n"}
,{"stream_name":"stdout","time":20.55873177,"data":"\n"}
,{"stream_name":"stdout","time":20.558735276,"data":"    def __call__(self, *args, **kwargs):\n"}
,{"stream_name":"stdout","time":20.558739272,"data":"        # An attempt to launch an unconfigured kernel\n"}
,{"stream_name":"stdout","time":20.558743054,"data":"\u003e       raise ValueError(missing_launch_config_msg)\n"}
,{"stream_name":"stdout","time":20.558746821,"data":"E       ValueError: \n"}
,{"stream_name":"stdout","time":20.558750449,"data":"E       Kernel launch configuration was not specified. Use the syntax:\n"}
,{"stream_name":"stdout","time":20.558754377,"data":"E       \n"}
,{"stream_name":"stdout","time":20.558758301,"data":"E       kernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n"}
,{"stream_name":"stdout","time":20.55876191,"data":"E       \n"}
,{"stream_name":"stdout","time":20.558765358,"data":"E       See https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n"}
,{"stream_name":"stdout","time":20.558769433,"data":"\n"}
,{"stream_name":"stdout","time":20.558772756,"data":"/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:715: ValueError\n"}
,{"stream_name":"stdout","time":20.558776474,"data":"----------------------------- Captured stdout call -----------------------------\n"}
,{"stream_name":"stdout","time":20.558779969,"data":"Running test: test_no_cpu_transfers_in_loop\n"}
,{"stream_name":"stdout","time":20.558783669,"data":"Finalizing network structure and validating topology...\n"}
,{"stream_name":"stdout","time":20.558787516,"data":"✅ Network topology is valid.\n"}
,{"stream_name":"stdout","time":20.558791811,"data":"✅ GPUMemoryPool initialized:\n"}
,{"stream_name":"stdout","time":20.558795433,"data":"   - Segments: 2\n"}
,{"stream_name":"stdout","time":20.558799119,"data":"   - Total cells: 150\n"}
,{"stream_name":"stdout","time":20.558803261,"data":"   - Ghost cells: 3\n"}
,{"stream_name":"stdout","time":20.558806895,"data":"   - Compute Capability: (6, 0)\n"}
,{"stream_name":"stdout","time":20.558810494,"data":"   - CUDA streams: Enabled\n"}
,{"stream_name":"stdout","time":20.558814119,"data":"   - GPU memory allocated: 0.00 MB\n"}
,{"stream_name":"stdout","time":20.558817838,"data":"  - Preparing GPU topology for network coupling...\n"}
,{"stream_name":"stdout","time":21.040549386,"data":"    - GPU topology prepared and transferred.\n"}
,{"stream_name":"stdout","time":21.040581343,"data":"__________________________ test_mass_conservation_gpu __________________________\n"}
,{"stream_name":"stdout","time":21.040586193,"data":"\n"}
,{"stream_name":"stdout","time":21.040590311,"data":"    def test_mass_conservation_gpu():\n"}
,{"stream_name":"stdout","time":21.040594344,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":21.040598276,"data":"        Verifies that the total mass (rho) in the system is conserved on the GPU\n"}
,{"stream_name":"stdout","time":21.040602479,"data":"        when using reflective boundary conditions.\n"}
,{"stream_name":"stdout","time":21.040607927,"data":"        \"\"\"\n"}
,{"stream_name":"stdout","time":21.040611556,"data":"        print(\"Running test: test_mass_conservation_gpu\")\n"}
,{"stream_name":"stdout","time":21.040615004,"data":"    \n"}
,{"stream_name":"stdout","time":21.040617269,"data":"        config = create_test_config()\n"}
,{"stream_name":"stdout","time":21.040619756,"data":"        # Use reflective \"wall\" boundary conditions to ensure mass is conserved\n"}
,{"stream_name":"stdout","time":21.040636248,"data":"        config.segments[0].boundary_conditions.left = ReflectiveBC()\n"}
,{"stream_name":"stdout","time":21.040638892,"data":"        config.segments[1].boundary_conditions.right = ReflectiveBC()\n"}
,{"stream_name":"stdout","time":21.040641334,"data":"    \n"}
,{"stream_name":"stdout","time":21.040643595,"data":"        network_grid = NetworkGrid.from_config(config)\n"}
,{"stream_name":"stdout","time":21.040646084,"data":"    \n"}
,{"stream_name":"stdout","time":21.040648342,"data":"        # Calculate initial mass from the config\n"}
,{"stream_name":"stdout","time":21.04065072,"data":"        initial_mass = 0.0\n"}
,{"stream_name":"stdout","time":21.040653044,"data":"        for seg_config in config.segments:\n"}
,{"stream_name":"stdout","time":21.040655492,"data":"            segment = network_grid.segments[seg_config.id]\n"}
,{"stream_name":"stdout","time":21.04065811,"data":"            ic_config = seg_config.initial_conditions.config\n"}
,{"stream_name":"stdout","time":21.040660688,"data":"            if isinstance(ic_config, UniformIC):\n"}
,{"stream_name":"stdout","time":21.040663025,"data":"                # Mass = density * length\n"}
,{"stream_name":"stdout","time":21.040665498,"data":"                initial_mass += ic_config.density * (segment['grid'].xmax - segment['grid'].xmin)\n"}
,{"stream_name":"stdout","time":21.040668004,"data":"    \n"}
,{"stream_name":"stdout","time":21.040670254,"data":"        runner = SimulationRunner(network_grid=network_grid, simulation_config=config, quiet=True)\n"}
,{"stream_name":"stdout","time":21.040672691,"data":"\u003e       results = runner.run()\n"}
,{"stream_name":"stdout","time":21.040675459,"data":"                  ^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":21.040677795,"data":"\n"}
,{"stream_name":"stdout","time":21.040680092,"data":"arz_model/tests/test_gpu_only_integration.py:196: \n"}
,{"stream_name":"stdout","time":21.040682475,"data":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"}
,{"stream_name":"stdout","time":21.04068496,"data":"arz_model/simulation/runner.py:745: in run\n"}
,{"stream_name":"stdout","time":21.040687293,"data":"    return self.network_simulator.run(t_final=sim_t_final)\n"}
,{"stream_name":"stdout","time":21.040689641,"data":"           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":21.040692012,"data":"arz_model/simulation/execution/network_simulator.py:171: in run\n"}
,{"stream_name":"stdout","time":21.040694428,"data":"    d_U_out = strang_splitting_step_gpu_native(\n"}
,{"stream_name":"stdout","time":21.040696789,"data":"arz_model/numerics/time_integration.py:1199: in strang_splitting_step_gpu_native\n"}
,{"stream_name":"stdout","time":21.040699253,"data":"    d_U_ss = solve_hyperbolic_step_ssp_rk3_gpu_native(d_U_star, dt, grid, params, gpu_pool, seg_id, current_time)\n"}
,{"stream_name":"stdout","time":21.040701723,"data":"             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"}
,{"stream_name":"stdout","time":21.040705479,"data":"arz_model/numerics/time_integration.py:1246: in solve_hyperbolic_step_ssp_rk3_gpu_native\n"}
,{"stream_name":"stdout","time":21.040707979,"data":"    ssp_rk3_stage_1_kernel(d_U_in, L_U0, dt, d_U1)\n"}
,{"stream_name":"stdout","time":21.040710334,"data":"_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ \n"}
,{"stream_name":"stdout","time":21.040712846,"data":"\n"}
,{"stream_name":"stdout","time":21.040719132,"data":"self = CUDADispatcher(\u003cfunction ssp_rk3_stage_1_kernel at 0x7c5537ed18a0\u003e)\n"}
,{"stream_name":"stdout","time":21.040723051,"data":"args = (\u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c550c5c3b90\u003e, \u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c5507f3cd90\u003e, 0.01, \u003cnumba.cuda.cudadrv.devicearray.DeviceNDArray object at 0x7c5507f3dd50\u003e)\n"}
,{"stream_name":"stdout","time":21.040727952,"data":"kwargs = {}\n"}
,{"stream_name":"stdout","time":21.040730268,"data":"\n"}
,{"stream_name":"stdout","time":21.040732519,"data":"    def __call__(self, *args, **kwargs):\n"}
,{"stream_name":"stdout","time":21.040734866,"data":"        # An attempt to launch an unconfigured kernel\n"}
,{"stream_name":"stdout","time":21.040737211,"data":"\u003e       raise ValueError(missing_launch_config_msg)\n"}
,{"stream_name":"stdout","time":21.040739604,"data":"E       ValueError: \n"}
,{"stream_name":"stdout","time":21.040741937,"data":"E       Kernel launch configuration was not specified. Use the syntax:\n"}
,{"stream_name":"stdout","time":21.040744358,"data":"E       \n"}
,{"stream_name":"stdout","time":21.040746683,"data":"E       kernel_function[blockspergrid, threadsperblock](arg0, arg1, ..., argn)\n"}
,{"stream_name":"stdout","time":21.040749093,"data":"E       \n"}
,{"stream_name":"stdout","time":21.040751428,"data":"E       See https://numba.readthedocs.io/en/stable/cuda/kernels.html#kernel-invocation for help.\n"}
,{"stream_name":"stdout","time":21.040753879,"data":"\n"}
,{"stream_name":"stdout","time":21.040756111,"data":"/usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:715: ValueError\n"}
,{"stream_name":"stdout","time":21.040758524,"data":"----------------------------- Captured stdout call -----------------------------\n"}
,{"stream_name":"stdout","time":21.040760976,"data":"Running test: test_mass_conservation_gpu\n"}
,{"stream_name":"stdout","time":21.040763311,"data":"Finalizing network structure and validating topology...\n"}
,{"stream_name":"stdout","time":21.040765701,"data":"✅ Network topology is valid.\n"}
,{"stream_name":"stdout","time":21.040768876,"data":"✅ GPUMemoryPool initialized:\n"}
,{"stream_name":"stdout","time":21.040771274,"data":"   - Segments: 2\n"}
,{"stream_name":"stdout","time":21.040773584,"data":"   - Total cells: 150\n"}
,{"stream_name":"stdout","time":21.040775892,"data":"   - Ghost cells: 3\n"}
,{"stream_name":"stdout","time":21.040778158,"data":"   - Compute Capability: (6, 0)\n"}
,{"stream_name":"stdout","time":21.040780573,"data":"   - CUDA streams: Enabled\n"}
,{"stream_name":"stdout","time":21.040782871,"data":"   - GPU memory allocated: 0.00 MB\n"}
,{"stream_name":"stdout","time":21.040785242,"data":"  - Preparing GPU topology for network coupling...\n"}
,{"stream_name":"stdout","time":21.040787647,"data":"    - GPU topology prepared and transferred.\n"}
,{"stream_name":"stdout","time":21.040790086,"data":"=============================== warnings summary ===============================\n"}
,{"stream_name":"stdout","time":21.040792477,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040794876,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040797249,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040799644,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040802004,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040807095,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040809848,"data":"tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040812239,"data":"tests/test_gpu_only_integration.py::test_no_cpu_transfers_in_loop\n"}
,{"stream_name":"stdout","time":21.040814634,"data":"tests/test_gpu_only_integration.py::test_mass_conservation_gpu\n"}
,{"stream_name":"stdout","time":21.040817051,"data":"  /usr/local/lib/python3.11/dist-packages/numba_cuda/numba/cuda/dispatcher.py:579: NumbaPerformanceWarning: \u001b[1mGrid size 1 will likely result in GPU under-utilization due to low occupancy.\u001b[0m\n"}
,{"stream_name":"stdout","time":21.040819776,"data":"    warn(NumbaPerformanceWarning(msg))\n"}
,{"stream_name":"stdout","time":21.040822123,"data":"\n"}
,{"stream_name":"stdout","time":21.040824408,"data":"-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html\n"}
,{"stream_name":"stdout","time":21.040826835,"data":"=========================== short test summary info ============================\n"}
,{"stream_name":"stdout","time":21.040829243,"data":"FAILED arz_model/tests/test_gpu_only_integration.py::test_simulation_runs_end_to_end_on_gpu\n"}
,{"stream_name":"stdout","time":21.040831649,"data":"FAILED arz_model/tests/test_gpu_only_integration.py::test_no_cpu_transfers_in_loop\n"}
,{"stream_name":"stdout","time":21.040834063,"data":"FAILED arz_model/tests/test_gpu_only_integration.py::test_mass_conservation_gpu\n"}
,{"stream_name":"stdout","time":21.040836459,"data":"============= 3 failed, 17 passed, 1 skipped, 9 warnings in 8.40s ==============\n"}
,{"stream_name":"stdout","time":21.574044586,"data":"[WARNING] Target execution returned code: 1\n"}
,{"stream_name":"stdout","time":21.574153742,"data":"\n"}
,{"stream_name":"stdout","time":21.574167678,"data":"[STEP 4/4] Cleanup...\n"}
,{"stream_name":"stdout","time":21.574264121,"data":"Cleaning up cloned repository at /kaggle/working/Code-traffic-flow...\n"}
,{"stream_name":"stdout","time":21.583539705,"data":"[OK] Repository cleaned up.\n"}
,{"stream_name":"stdout","time":21.583565223,"data":"\n"}
,{"stream_name":"stdout","time":21.583570152,"data":"[FINAL] Test workflow completed\n"}
,{"stream_name":"stdout","time":21.583734838,"data":"\n"}
,{"stream_name":"stdout","time":21.583743353,"data":"================================================================================\n"}
,{"stream_name":"stdout","time":21.583747228,"data":"EXECUTION COMPLETED\n"}
,{"stream_name":"stdout","time":21.583750907,"data":"Check /kaggle/working/test_log.txt for details.\n"}
,{"stream_name":"stdout","time":21.583754643,"data":"================================================================================\n"}
,{"stream_name":"stderr","time":25.381796769,"data":"/usr/local/lib/python3.11/dist-packages/traitlets/traitlets.py:2915: FutureWarning: --Exporter.preprocessors=[\"nbconvert.preprocessors.ExtractOutputPreprocessor\"] for containers is deprecated in traitlets 5.0. You can pass `--Exporter.preprocessors item` ... multiple times to add items to a list.\n"}
,{"stream_name":"stderr","time":25.381853533,"data":"  warn(\n"}
,{"stream_name":"stderr","time":25.42284261,"data":"[NbConvertApp] Converting notebook __script__.ipynb to html\n"}
,{"stream_name":"stderr","time":26.548155092000002,"data":"[NbConvertApp] Writing 298633 bytes to __results__.html\n"}
]