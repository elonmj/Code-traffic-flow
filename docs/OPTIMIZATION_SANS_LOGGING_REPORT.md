# Optimisations Kaggle - Sans Logging (Respect √† St Thomas d'Aquin)

**Date**: 2025-11-19  
**Branche**: `experiment/kaggle-rl-training`  
**Philosophie**: Investigation par lecture de code, pas instrumentation

---

## ‚úÖ Optimisations Impl√©ment√©es

### 1. ‚è±Ô∏è Timeout Configurable

**Probl√®me**: Timeout hardcod√© ‚Üí impossible pour le user de contr√¥ler  
**Solution**: Ajout de `timeout_seconds` dans les configs Pydantic

#### Code Modifi√©

**`arz_model/config/time_config.py`**:
```python
timeout_seconds: Optional[float] = Field(
    default=None,
    description="Maximum wall-clock time in seconds (None = infinite). Useful for Kaggle kernels."
)
```

**`Code_RL/training/config/training_config.py`**:
```python
class EvaluationStrategy(BaseModel):
    timeout_seconds: Optional[float] = Field(
        default=None, 
        description="Timeout max (s) pour √©valuation (None = infini)"
    )

def kaggle_gpu_config(...):
    return TrainingConfig(
        evaluation_strategy=EvaluationStrategy(
            timeout_seconds=300.0  # 5 min pour √©viter inactivit√© Kaggle
        )
    )
```

**Impact**: User peut maintenant d√©finir `timeout_seconds=300.0` pour √©viter timeouts Kaggle

---

### 2. üöÄ R√©utilisation d'Env dans Sanity Checker

**Probl√®me Identifi√©** (analyse Kaggle log):
- Check #4 (rollout): Cr√©e env ‚Üí 1 reconstruction (12MB GPU)
- Check #5 (reward diversity): Cr√©e NOUVEL env ‚Üí 1 reconstruction (2MB GPU)
- **Total gaspillage**: 2 reconstructions, ~5-7 secondes, 30% du temps setup

**Solution Architecturale** (sans logging):
- Cr√©er **UN SEUL** env partag√©
- Passer l'env √† checks #4 et #5
- Fermer apr√®s tous les checks

#### Code Modifi√©

**`Code_RL/training/core/sanity_checker.py`**:
```python
def run_all_checks(self) -> List[SanityCheckResult]:
    # ...checks 1-3...
    
    # üöÄ OPTIMIZATION: R√©utiliser UN SEUL env pour checks #4 et #5
    shared_env = None
    if self.sanity_config.enabled:
        shared_env = self._create_test_env()  # Cr√©er UNE FOIS
    
    if self.sanity_config.enabled:
        self.results.append(self._check_environment_rollout(env=shared_env))
    
    if self.sanity_config.enabled:
        self.results.append(self._check_reward_diversity(env=shared_env))
    
    # Cleanup
    if shared_env is not None:
        shared_env.close()
```

**Signatures Modifi√©es**:
```python
def _check_environment_rollout(self, env=None) -> SanityCheckResult:
    env_created = False
    if env is None:
        env = self._create_test_env()
        env_created = True
    # ... tests ...
    finally:
        if env_created:
            env.close()

def _check_reward_diversity(self, env=None) -> SanityCheckResult:
    # M√™me pattern
```

**Gains Estim√©s**:
- **Reconstructions**: 9 ‚Üí 8 (-11%)
- **Temps setup**: 44s ‚Üí 39s (-5s, -11%)
- **Overhead total**: 30% ‚Üí 26% (-4 points)

---

## üîç Investigation make_vec_env() (Sans Logging)

### M√©thodologie: Lecture de Code Source SB3

**Chemin**: `C:\Users\JOSAPHAT\AppData\Roaming\Python\Python312\site-packages\stable_baselines3\common\env_util.py`

**Code Critique**:
```python
def make_vec_env(env_id, n_envs=1, ...):
    vec_env = vec_env_cls([make_env(i) for i in range(n_envs)], **vec_env_kwargs)
    return vec_env
```

### R√©sultats d'Investigation

**Avec `n_envs=1`**:
- ‚úÖ Cr√©e **EXACTEMENT 1** environnement (list comprehension)
- ‚úÖ Pas de v√©rifications cach√©es trouv√©es
- ‚úÖ Pas de warm-up automatique

**EvalCallback**:
```python
# Code_RL/training/core/trainer.py:389
eval_callback = EvalCallback(
    self.eval_env,  # ‚Üê Re√ßoit env existant
    ...
)
```
- ‚úÖ Re√ßoit `self.eval_env` d√©j√† cr√©√©
- ‚úÖ Ne cr√©e PAS d'env suppl√©mentaire

### Conclusion: Myst√®re des 6-7 Envs Inexpliqu√©s

**Hypoth√®ses** (sans pouvoir confirmer sans instrumentation):
1. **GPU Pool Warm-up**: Premi√®re allocation GPU d√©clenche plusieurs tentatives internes
2. **Python Garbage Collection**: Objets temporaires cr√©√©s/d√©truits pendant import
3. **Numba JIT**: Compilation kernels GPU peut construire objets temporaires
4. **SB3 Internal Checks**: Possible v√©rification silencieuse non visible dans env_util.py

**D√©cision**: Ne PAS ajouter de logging (respect philosophie). Se concentrer sur causes **confirm√©es** (sanity_checker).

---

## üìä Comparaison Avant/Apr√®s

### Kaggle Log Original (commit d67602f)
```
Timeline Breakdown:
- Setup overhead: 56% (83.3s) - sanity checks, imports, network builds
- Wasteful reconstructions: 29% (44s) - 7 unnecessary builds
- Useful training: 11% (16s) - actual learning
- Evaluation: 4% (5.7s) - model validation
```

**Reconstructions D√©taill√©es**:
- Sanity check #4 (rollout): 1 reconstruction ‚ùå
- Sanity check #5 (reward): 1 reconstruction ‚ùå  
- make_vec_env() mystery: 6-7 reconstructions ‚ùì (non r√©solu)
- Training env: 1 reconstruction ‚úÖ (n√©cessaire)
- Eval env: 1 reconstruction ‚úÖ (n√©cessaire)

### Apr√®s Optimisation (estim√©)
```
Timeline Breakdown:
- Setup overhead: 52% (78s) - sanity checks optimis√©es
- Wasteful reconstructions: 26% (39s) - 6 unnecessary builds (-1 build)
- Useful training: 11% (16s) - unchanged
- Evaluation: 4% (5.7s) - unchanged
- TOTAL: ~150s ‚Üí ~145s (-5s, -3.3%)
```

**Reconstructions Optimis√©es**:
- Sanity checks: 1 reconstruction ‚úÖ (partag√© entre #4 et #5)
- make_vec_env() mystery: 6-7 reconstructions ‚ùì (non r√©solu)
- Training env: 1 reconstruction ‚úÖ
- Eval env: 1 reconstruction ‚úÖ

---

## üèóÔ∏è Architectures Long Terme (TODO)

### 1. GPU Pool Singleton Pattern
**Objectif**: Cache global pour √©viter r√©allocations GPU

```python
class GPUMemoryPoolSingleton:
    _instance = None
    _pool = None
    
    @classmethod
    def get_pool(cls, segment_ids, N_per_segment):
        if cls._pool is None:
            cls._pool = GPUMemoryPool(segment_ids, N_per_segment)
        return cls._pool
```

**Gain estim√©**: -20-30s (√©liminer 6-7 reconstructions myst√©rieuses)

### 2. Environment Factory Pooling
**Objectif**: R√©utiliser envs au lieu de reconstruire

```python
class EnvironmentPool:
    def __init__(self, factory, max_size=3):
        self.factory = factory
        self.available = []
        self.in_use = []
    
    def acquire(self):
        if self.available:
            return self.available.pop()
        return self.factory()
    
    def release(self, env):
        env.reset()
        self.available.append(env)
```

**Gain estim√©**: -10-15s (r√©utiliser envs entre sanity checks et training)

---

## üéØ Prochaines √âtapes

1. **Tester optimisations** sur Kaggle
2. **Mesurer gains r√©els** (sans logging, juste timing total)
3. **Si gains insuffisants**: Impl√©menter GPU Pool Singleton
4. **Documentation**: Mettre √† jour RL_TRAINING_SURVIVAL_GUIDE.md

---

## üìù Notes Philosophiques

**Respect √† St Thomas d'Aquin**: "Entia non sunt multiplicanda praeter necessitatem"  
‚Üí Ne pas multiplier les logs sans n√©cessit√©. Investigation par LECTURE, pas INSTRUMENTATION.

**Approche adopt√©e**:
- ‚úÖ Lire code source SB3
- ‚úÖ Analyser patterns d'allocation
- ‚úÖ Optimiser causes confirm√©es
- ‚ùå PAS de print() debugging
- ‚ùå PAS de logging suppl√©mentaire

Cette approche philosophique force une compr√©hension PROFONDE du code plut√¥t qu'une d√©pendance aux logs.
