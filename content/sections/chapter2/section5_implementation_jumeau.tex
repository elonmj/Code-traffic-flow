\section{Implémentation du Jumeau Numérique de Trafic}
\label{ch:implementation_jumeau}

% Introduction synthétisée
La construction d'un jumeau numérique fonctionnel et prédictif pour un réseau de transport urbain complexe comme celui de Lagos, au Nigéria, représente l'aboutissement de la modélisation théorique et des schémas numériques décrits précédemment. Cette section fait le pont entre la théorie et la pratique, en détaillant la mise en œuvre concrète du simulateur de trafic multi-classes. Les fondements mathématiques et la robustesse de la méthode numérique, désormais établis et relégués en \textbf{Annexe \ref{annexe:fondements_math_num}}, nous donnent la confiance nécessaire pour construire cet outil.

Cette section raconte donc l'histoire de la transformation d'un modèle mathématique en un outil opérationnel, capable de simuler et d'anticiper les dynamiques de trafic dans l'un des environnements urbains les plus exigeants au monde. Il s'articule en trois temps :
\begin{enumerate}
       \item \textbf{Choix et Caractérisation du Site d'Étude :} Justification du choix du corridor de Victoria Island à Lagos comme laboratoire représentatif.
       \item \textbf{Acquisition et Intégration des Données du Monde Réel :} Capture de la réalité physique (OpenStreetMap) et dynamique (API TomTom) du réseau.
       \item \textbf{Développement d'une Architecture Logicielle Modulaire :} Description de la structure du code, des choix technologiques et des optimisations de performance.
\end{enumerate}

\subsection{Sélection et Caractérisation du Corridor d'Étude}
\label{sec:selection_corridor}

Le choix du terrain d'expérimentation est une étape fondatrice qui conditionne la pertinence et la validité des résultats. Notre sélection s'est portée sur un corridor majeur de Victoria Island (VI), le centre névralgique des affaires de Lagos, Nigeria. Ce choix repose sur quatre critères principaux qui en font un laboratoire idéal pour notre étude.

\begin{enumerate}
       \item \textbf{Mixité et Hétérogénéité du Trafic :} Le corridor présente un mélange de véhicules extrêmement varié (voitures particulières, bus, tricycles) avec une proportion très significative de motos-taxis ("Okadas"). Cette composition, documentée par des études locales \parencite{LUDI:2020}, est représentative du trafic ouest-africain, ce qui en fait un excellent cas d'étude pour valider notre modèle ARZ multi-classes.

       \item \textbf{Congestion Chronique :} En tant que quartier d'affaires, VI subit des embouteillages quotidiens intenses, particulièrement lors des heures de pointe étendues. Cette situation nous garantit d'observer toute la gamme des états de trafic, du flux libre à la congestion saturée, et de pouvoir étudier les phénomènes de \textit{creeping} et de \textit{gap-filling} des motos en conditions réelles.

       \item \textbf{Intersections Régulées :} L'axe principal du corridor est ponctué de plusieurs carrefours d'envergure contrôlés par des feux de signalisation. Ces intersections constituent les points de contrôle que notre futur agent RL visera à optimiser.

       \item \textbf{Disponibilité des Données :} Lagos, en tant que mégapole, bénéficie d'une meilleure couverture de données par des services commerciaux comme TomTom, ce qui est indispensable pour la calibration et la validation d'un modèle qui se veut ancré dans la réalité.
\end{enumerate}

\subsection{De la Carte à la Simulation : Acquisition et Traitement des Données}
\label{sec:data_acquisition}

La fidélité d'un jumeau numérique dépend entièrement de la qualité et de la pertinence des données qui l'alimentent. Pour notre cas d'étude à Lagos, nous avons combiné deux sources de données complémentaires pour construire une représentation numérique riche du réseau et de son utilisation.

\subsubsection{Modélisation du Réseau Routier Statique avec OpenStreetMap}
\textit{OpenStreetMap} (OSM) est une base de données géospatiale collaborative qui offre une couverture mondiale et un niveau de détail souvent supérieur aux services cartographiques propriétaires.

\paragraph{Extraction de la Topologie via OSMnx}
Nous avons utilisé la bibliothèque Python \texttt{osmnx} pour interroger la base de données OpenStreetMap. En ciblant le centre géographique du corridor, nous avons extrait un graphe routier directionnel comprenant \textbf{75 segments uniques}.
\begin{verbatim}
import osmnx as ox
place_name = "Victoria Island, Lagos, Nigeria"
graph = ox.graph_from_place(place_name, network_type='drive')
\end{verbatim}
Cette première étape a mis en lumière une lacune de données attendue : les attributs physiques nécessaires à notre modèle, tels que le nombre de voies (`lanes`) et la qualité du revêtement (`surface`), étaient presque totalement absents.

\paragraph{Qualification Manuelle et Enrichissement des Données}
Pour transformer le squelette topologique en un modèle physiquement réaliste, nous avons procédé à un enrichissement des données en utilisant Google Street View comme source de "vérité terrain".
\begin{itemize}
       \item \textbf{Nombre de Voies (`lanes\_manual`):} Pour chaque segment, le nombre de voies a été compté visuellement.
       \item \textbf{Qualité de l'Infrastructure (`Rx\_manual`):} Une note de qualité a été assignée à chaque segment en utilisant une échelle de 1 (excellent) à 4 (dégradé).
\end{itemize}
Ce processus a abouti à la création d'un fichier de travail qui constitue la base de données statique du jumeau numérique, combinant les données extraites d'OSM et nos enrichissements manuels.

\subsubsection{Acquisition des Données de Trafic Dynamique avec TomTom}
Si OSM fournit la structure statique, les données de trafic en temps réel sont indispensables pour capturer sa dynamique.

\paragraph{Architecture du Système de Collecte}
Un collecteur de données robuste a été développé en Python pour interroger l'API \textit{TomTom Traffic}. Pour garantir une collecte continue (24/7), le script a été déployé sur un serveur cloud via le service \textbf{PythonAnywhere}, en utilisant une fonctionnalité "Always-on task". Une flotte de \textbf{10 clés API} a été mise en place en rotation pour respecter les quotas journaliers (2 500 requêtes/clé/jour) et assurer la pérennité de l'acquisition. Le service \textit{Flow Segment Data} est utilisé pour récupérer la vitesse actuelle (`currentSpeed`) et la vitesse en flux libre (`freeFlowSpeed`) pour les 75 segments du corridor.

\paragraph{Conception de la Stratégie de Collecte Adaptative}
Une collecte à intervalle fixe est sous-optimale. Nous avons implémenté une stratégie qui ajuste sa fréquence aux rythmes de la ville :
\begin{itemize}
       \item \textbf{Heures de Pointe (06h-10h \& 16h-22h):} Intervalle de 3 minutes.
       \item \textbf{Journée Normale (10h-16h):} Intervalle de 5 minutes.
       \item \textbf{Nuit (22h-06h):} Intervalle de 15 minutes.
\end{itemize}
Cette approche concentre la puissance de collecte sur les périodes les plus critiques pour la calibration et la validation, tout en préservant les quotas API. Un test de 24 heures a validé la robustesse technique du collecteur et sa capacité à capturer la courbe de congestion journalière typique du corridor.

\subsection{Architecture et Développement du Simulateur}
\label{sec:simulator_architecture}

Le passage d'un modèle mathématique complexe à un outil de simulation performant représente un défi d'ingénierie logicielle majeur. Le simulateur a été développé en Python, en s'appuyant sur l'écosystème scientifique moderne pour construire une architecture à la fois modulaire, maintenable et hautement performante.

\subsubsection{Une Stratégie de Performance à Trois Niveaux}
La simulation de phénomènes décrits par des équations aux dérivées partielles est une tâche de calcul intensif. Pour atteindre les performances requises, une simple implémentation en Python est insuffisante. Nous avons donc adopté une stratégie d'optimisation à trois niveaux, combinant le meilleur des mondes de la simplicité de développement et de la performance brute.

\paragraph{Niveau 1 : Vectorisation avec NumPy}
La base de notre stratégie de performance repose sur la \textbf{vectorisation} systématique des opérations à l'aide de la bibliothèque NumPy. Au lieu d'itérer sur chaque cellule de la grille de calcul, les opérations sont appliquées simultanément à des tableaux entiers représentant l'état de tous les segments du réseau. Cette approche tire parti des routines C et Fortran optimisées de NumPy, offrant un premier gain de performance substantiel par rapport à du code Python natif.

\paragraph{Niveau 2 : Compilation Just-in-Time (JIT) avec Numba}
Pour éliminer l'overhead de l'interpréteur Python dans les boucles de calcul les plus critiques, nous avons utilisé le compilateur \textbf{Numba}. En ajoutant le décorateur \texttt{@njit} (Just-in-Time en mode "no-python"), les fonctions Python critiques sont compilées à la volée en code machine natif, atteignant des performances proches de celles du C ou du Fortran.
\begin{verbatim}
from numba import njit

@njit
def calculate_pressure(rho_m, rho_c, alpha, ...):
    # Cette fonction est compilée en code machine optimisé
    # lors de son premier appel.
    ...
\end{verbatim}
Cette technique a été appliquée à toutes les fonctions constituant le cœur physique du modèle ARZ (calcul de pression, vitesse d'équilibre, flux numériques) et aux schémas de reconstruction WENO sur CPU.

\paragraph{Niveau 3 : Parallélisme Massif sur GPU avec CUDA}
Pour les simulations à très grande échelle et les campagnes de validation exigeantes, une troisième couche d'optimisation a été développée pour exploiter le parallélisme massif des processeurs graphiques (GPU). Grâce à l'intégration de Numba avec l'architecture \textbf{CUDA} de NVIDIA, nous avons porté les algorithmes les plus coûteux sur GPU.
\begin{verbatim}
from numba import cuda

@cuda.jit
def weno_cuda_kernel(U, U_reconstructed, ...):
    # Ce kernel est exécuté par des milliers de threads
    # en parallèle sur le GPU.
    ...
\end{verbatim}
Des kernels CUDA spécifiques ont été écrits pour la reconstruction WENO et l'intégrateur temporel SSP-RK3, permettant de diviser drastiquement les temps de calcul pour les réseaux de grande taille. Cette stratégie hybride CPU/GPU offre une flexibilité cruciale, permettant d'adapter la puissance de calcul aux besoins de la simulation.

\subsubsection{Architecture Modulaire et Scientifique}
Le code source est organisé selon une architecture en couches rigoureuse au sein du package principal \texttt{arz\_model}, où chaque module encapsule une responsabilité scientifique et technique claire.

\begin{description}
       \item[\texttt{core/}] Constitue le cœur physique du simulateur. Il implémente la logique du modèle ARZ étendu, incluant les fonctions de pression, de vitesse d'équilibre et de temps de relaxation, toutes optimisées avec Numba.

       \item[\texttt{numerics/}] Contient l'implémentation des schémas numériques à haute résolution. Il est subdivisé en \texttt{reconstruction/} (pour les schémas WENO CPU et GPU) et \texttt{time\_integrators/} (pour l'avancement temporel SSP-RK3). Le sous-module \texttt{gpu/} regroupe les kernels CUDA spécifiques.

       \item[\texttt{calibration/}] Un module scientifique clé, dédié à l'estimation automatique des paramètres du modèle. Face à la nature non-différentiable du système (due aux solveurs de Riemann), il implémente des optimiseurs \textit{gradient-free} (Nelder-Mead, Évolution Différentielle) pour ajuster les paramètres du modèle en se basant sur les données réelles.

       \item[\texttt{simulation/}] Agit comme l'orchestrateur des simulations. Il gère les conditions aux limites, le couplage entre les différents segments du réseau et le déroulement temporel de la simulation.

       \item[\texttt{grid/}] Responsable de la discrétisation spatiale du réseau routier et de la gestion de la grille de calcul.

       \item[\texttt{validation/}] Regroupe les scripts et outils pour les tests de validation numérique (e.g., tests de Riemann) et l'intégration avec des infrastructures externes.

       \item[\texttt{io/}, \texttt{visualization/}, \texttt{analysis/}] Modules de support assurant respectivement la gestion des entrées/sorties, la visualisation des résultats et les analyses post-simulation.
\end{description}
Cette architecture découplée et orientée objet garantit la maintenabilité, la testabilité et l'évolutivité du simulateur.

\subsubsection{Infrastructure de Validation Cloud via Kaggle}
Pour surmonter les limitations matérielles locales, notamment l'absence de GPU haute performance pour les validations intensives, une infrastructure de validation cloud a été mise en place en utilisant la plateforme \textbf{Kaggle}. Un module de gestion (\texttt{validation/kaggle\_manager.py}) automatise le flux de travail suivant :
\begin{enumerate}
       \item \textbf{Packaging et Upload :} Le code source du simulateur est packagé et téléversé sur Kaggle Datasets.
       \item \textbf{Exécution à Distance :} Des notebooks Kaggle sont exécutés en mode GPU (utilisant des accélérateurs comme le Tesla P100), lançant des campagnes de simulation et de validation.
       \item \textbf{Récupération des Résultats :} Les résultats (fichiers de données, figures, logs) sont automatiquement rapatriés pour analyse locale.
\end{enumerate}
Cette approche ingénieuse a permis de mener à bien les validations numériques complexes du chapitre 7 sans nécessiter d'investissement matériel coûteux, illustrant une pratique de recherche moderne et pragmatique.

\subsubsection{Écosystème Logiciel Intégré}
La Figure~\ref{fig:tech_stack} présente l'écosystème logiciel complet mobilisé pour construire ce simulateur. Cette architecture multi-couches reflète la complexité technique du projet, combinant des outils de calcul scientifique haute performance, d'apprentissage automatique, de géospatial, et d'infrastructure cloud. Chaque composant a été sélectionné pour sa robustesse, sa performance et son adoption par la communauté scientifique.

\begin{figure}[htbp]
       \centering
       \begin{tikzpicture}[
                     % Style pour les boxes avec logos PNG
                     logobox/.style={rectangle, rounded corners=3pt, draw=black!25, thick,
                                   minimum height=1cm, minimum width=2.3cm, fill=white,
                                   inner sep=1pt},
                     % Style pour les boxes avec texte
                     textbox/.style={rectangle, rounded corners=3pt, draw=black!25, thick,
                                   minimum height=1cm, minimum width=2.3cm,
                                   font=\small\sffamily\bfseries, text centered},
                     layer/.style={font=\small\sffamily\bfseries, text=black!65},
                     node distance=0.18cm
              ]
              % Layer 1: Langage & Environnement
              \node[layer] at (-2.2, 4) {Langage};
              \node[logobox, fill=blue!7] (python) at (0.3, 4) {\includegraphics[height=0.75cm]{images/logos/python.png}};
              \node[logobox, fill=blue!7, right=of python] (jupyter) {\includegraphics[height=0.7cm]{images/logos/jupyter.png}};
              \node[logobox, fill=blue!7, right=of jupyter] (git) {\includegraphics[height=0.65cm]{images/logos/git.png}};

              % Layer 2: Calcul Scientifique & Performance
              \node[layer] at (-2.2, 2.9) {Calcul};
              \node[logobox, fill=green!8] (numpy) at (0, 2.9) {\includegraphics[height=0.7cm]{images/logos/numpy_full.png}};
              \node[logobox, fill=green!8, right=of numpy] (scipy) {\includegraphics[height=0.7cm]{images/logos/scipy.png}};
              \node[logobox, fill=green!12, right=of scipy] (numba) {\includegraphics[height=0.75cm]{images/logos/numba.png}};
              \node[logobox, fill=green!16, right=of numba] (cuda) {\includegraphics[height=0.75cm]{images/logos/cuda.png}};

              % Layer 3: Apprentissage par Renforcement
              \node[layer] at (-2.2, 1.8) {RL};
              \node[logobox, fill=orange!10] (gym) at (1.2, 1.8) {\includegraphics[height=0.7cm]{images/logos/gymnasium.png}};
              \node[logobox, fill=orange!10, right=of gym] (sb3) {\includegraphics[height=0.75cm]{images/logos/sb3.png}};

              % Layer 4: Visualisation
              \node[layer] at (-2.2, 0.7) {Viz};
              \node[logobox, fill=blue!9] (mpl) at (0, 0.7) {\includegraphics[height=0.65cm]{images/logos/matplotlib.png}};
              \node[logobox, fill=blue!9, right=of mpl] (seaborn) {\includegraphics[height=0.7cm]{images/logos/seaborn.png}};
              \node[logobox, fill=blue!9, right=of seaborn] (plotly) {\includegraphics[height=0.7cm]{images/logos/plotly.png}};

              % Layer 5: Données Géospatiales & Temps Réel
              \node[layer] at (-2.2, -0.4) {Données};
              \node[logobox, fill=red!9] (pandas) at (0, -0.4) {\includegraphics[height=0.65cm]{images/logos/pandas_full.png}};
              \node[logobox, fill=red!9, right=of pandas] (osmnx) {\includegraphics[height=0.75cm]{images/logos/osmnx.png}};
              \node[logobox, fill=red!9, right=of osmnx] (tomtom) {\includegraphics[height=0.7cm]{images/logos/tomtom.png}};

              % Layer 6: Infrastructure Cloud
              \node[layer] at (-2.2, -1.5) {Cloud};
              \node[logobox, fill=yellow!15] (kaggle) at (1.2, -1.5) {\includegraphics[height=0.6cm]{images/logos/kaggle.png}};
              \node[logobox, fill=yellow!15, right=of kaggle] (pythonanywhere) {\includegraphics[height=0.65cm]{images/logos/pythonanywhere.png}};

              % Encadrement principal sobre
              \draw[gray!30, thick, rounded corners=4pt]
              (-3, 4.6) rectangle (9.5, -2.1);

              % Annotations minimalistes sur le côté
              \node[font=\scriptsize, text=black!50, align=left, anchor=west] at (9.8, 2.9)
              {\textit{Performance}};
              \node[font=\scriptsize, text=black!50, align=left, anchor=west] at (9.8, -0.4)
              {\textit{Real-time}};
              \node[font=\scriptsize, text=black!50, align=left, anchor=west] at (9.8, -1.5)
              {\textit{GPU Cloud}};
       \end{tikzpicture}
       \caption{Écosystème logiciel du simulateur ARZ. L'architecture repose sur six couches technologiques : le langage Python et son environnement de développement (Git, Jupyter) ; les bibliothèques de calcul scientifique avec optimisation progressive (NumPy → SciPy → Numba → CUDA) ; les frameworks d'apprentissage par renforcement (Gymnasium, Stable-Baselines3) ; les outils de visualisation (Matplotlib, Seaborn, Plotly) ; les sources de données géospatiales et temps réel (Pandas, OSMnx, TomTom API) ; et l'infrastructure cloud pour le calcul GPU distribué (Kaggle, PythonAnywhere). Cette stack illustre une approche rigoureuse et moderne du calcul scientifique haute performance en Python.}
       \label{fig:tech_stack}
\end{figure}

\subsection{Synthèse de la Section}
\label{sec:conclusion_ch5}

Au terme de cette section, nous avons franchi une étape décisive en passant de la théorie à la pratique. Nous avons détaillé la construction et la caractérisation d'un environnement de simulation complet pour le corridor de Victoria Island, en nous basant sur des données réelles et spécifiques au contexte. La topologie statique du réseau a été définie et enrichie, et la chaîne de collecte de données dynamiques a été validée. L'architecture logicielle, qui se distingue par sa modularité et sa stratégie d'optimisation de performance à trois niveaux (NumPy, Numba, et CUDA), a été présentée en détail.

Ce jumeau numérique, fondé sur les bases mathématiques et numériques rigoureuses établies en \textbf{Annexe \ref{annexe:fondements_math_num}}, constitue désormais une base solide et fiable. Il est prêt à être utilisé dans les phases suivantes : la calibration fine des paramètres comportementaux de notre modèle (Section~\ref{sec:entrainement_agents}), la conception de l'environnement d'apprentissage par renforcement (Section~\ref{sec:conception_implementation}), et l'évaluation de stratégies de contrôle innovantes (Section~\ref{sec:evaluation_robustesse}).

\begin{keypointsbox}[Points Clés de la Section 5]
       \begin{itemize}
              \item \textbf{Jumeau Numérique Opérationnel} : Un environnement de simulation complet pour le corridor de Victoria Island a été développé, transformant la théorie en un outil pratique.
              \item \textbf{Fondation sur Données Réelles} : Le simulateur est ancré dans la réalité grâce à la combinaison de la topologie statique d'OpenStreetMap (enrichie manuellement) et des données de trafic dynamiques de TomTom (collectées via une architecture adaptative et robuste).
              \item \textbf{Stratégie de Performance à Trois Niveaux} : La performance est assurée par une approche hybride : vectorisation \textbf{NumPy}, compilation JIT avec \textbf{Numba} pour le code CPU critique, et parallélisme massif sur \textbf{GPU} avec \textbf{CUDA} pour les calculs intensifs.
              \item \textbf{Architecture Modulaire et Scientifique} : Le code est structuré en modules découplés (`core`, `numerics`, `calibration`, `simulation`...) qui encapsulent des responsabilités scientifiques claires, garantissant maintenabilité et évolutivité.
              \item \textbf{Innovations Techniques} : Le projet intègre des solutions avancées telles qu'un module de \textbf{calibration automatique} avec des optimiseurs gradient-free et une \textbf{infrastructure de validation cloud} via Kaggle pour surmonter les limitations matérielles.
              \item \textbf{Prêt pour la Suite} : Ce jumeau numérique constitue la fondation robuste pour la calibration du modèle, l'entraînement de l'agent d'apprentissage par renforcement et l'évaluation de stratégies de contrôle.
       \end{itemize}
\end{keypointsbox}

